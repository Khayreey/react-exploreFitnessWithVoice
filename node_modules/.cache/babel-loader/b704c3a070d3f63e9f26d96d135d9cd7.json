{"ast":null,"code":"var _jsxFileName = \"H:\\\\React\\\\FREE-CODE-CAMP\\\\fitness\\\\src\\\\components\\\\MicrophoneSearch.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState } from 'react';\nimport micro from '../assets/icons/m.png';\nimport animated from '../assets/icons/m.gif';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { exGetOptions, fetchData } from '../utils/fetchData';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nconst MicrophoneSearch = props => {\n  _s();\n\n  const [search, setSearch] = useState('');\n  useEffect(() => {\n    // avoid to call api when component re-evaluate or first time render\n    if (!search) {\n      return;\n    } else {\n      const searchHandler = async () => {\n        window.scrollTo({\n          top: 1300,\n          behavior: 'smooth'\n        });\n        const exData = await fetchData('https://exercisedb.p.rapidapi.com/exercises', exGetOptions);\n        const searchedExercices = exData.filter(ex => ex.name.toLowerCase().includes(search) || ex.target.toLowerCase().includes(search) || ex.equipment.toLowerCase().includes(search) || ex.bodyPart.toLowerCase().includes(search));\n        console.log(searchedExercices.length);\n\n        if (searchedExercices.length === 0) {\n          props.setNoExercisesFound(true);\n        } else {\n          props.setExercices(searchedExercices);\n        }\n\n        setSearch('');\n      };\n\n      searchHandler();\n    }\n  }, [search]);\n  const commands = [{\n    command: 'reset',\n    callback: () => resetTranscript()\n  } // {\n  //   command: 'shut up',\n  //   callback: () => setMessage('I wasn\\'t talking.')\n  // },\n  // {\n  //   command: 'Hello',\n  //   callback: () => setMessage('Hi there!')\n  // },\n  ];\n  const {\n    transcript,\n    interimTranscript,\n    finalTranscript,\n    resetTranscript,\n    listening\n  } = useSpeechRecognition({\n    commands\n  });\n  useEffect(() => {\n    if (finalTranscript !== '') {\n      console.log('Got final result:', finalTranscript);\n    }\n\n    if (transcript.length > 0) {\n      setSearch(transcript);\n    }\n  }, [interimTranscript, finalTranscript, transcript]);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\n  }\n\n  const listenContinuously = () => {\n    SpeechRecognition.startListening({\n      language: 'en-GB'\n    });\n  };\n\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [listening ? /*#__PURE__*/_jsxDEV(\"img\", {\n      src: animated,\n      onClick: SpeechRecognition.stopListening,\n      className: \"microphone\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 91,\n      columnNumber: 18\n    }, this) : /*#__PURE__*/_jsxDEV(\"img\", {\n      src: micro,\n      onClick: listenContinuously,\n      className: \"microphone\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 92,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: transcript\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 3\n    }, this)]\n  }, void 0, true);\n};\n\n_s(MicrophoneSearch, \"VrfmD45elF546M0Y7hYhkE4SxQI=\", false, function () {\n  return [useSpeechRecognition];\n});\n\n_c = MicrophoneSearch;\nexport default MicrophoneSearch;\n\nvar _c;\n\n$RefreshReg$(_c, \"MicrophoneSearch\");","map":{"version":3,"names":["React","useEffect","useState","micro","animated","SpeechRecognition","useSpeechRecognition","exGetOptions","fetchData","MicrophoneSearch","props","search","setSearch","searchHandler","window","scrollTo","top","behavior","exData","searchedExercices","filter","ex","name","toLowerCase","includes","target","equipment","bodyPart","console","log","length","setNoExercisesFound","setExercices","commands","command","callback","resetTranscript","transcript","interimTranscript","finalTranscript","listening","browserSupportsSpeechRecognition","listenContinuously","startListening","language","stopListening"],"sources":["H:/React/FREE-CODE-CAMP/fitness/src/components/MicrophoneSearch.js"],"sourcesContent":["import React , {useEffect , useState} from 'react'\r\nimport micro from '../assets/icons/m.png'\r\nimport animated from '../assets/icons/m.gif'\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\nimport {exGetOptions,fetchData} from '../utils/fetchData'\r\nconst MicrophoneSearch = (props) => {\r\n\r\n  const [search , setSearch] = useState('')\r\n  \r\n  useEffect( ()=>{\r\n\r\n    // avoid to call api when component re-evaluate or first time render\r\n    if(!search)\r\n    {\r\n        return\r\n    }\r\n\r\n    else {\r\n        \r\n        const searchHandler = async ()=>{\r\n            window.scrollTo({top : 1300 , behavior :'smooth'})\r\n            const exData = await fetchData('https://exercisedb.p.rapidapi.com/exercises', exGetOptions)\r\n            const searchedExercices = exData.filter((ex)=>\r\n             ex.name.toLowerCase().includes(search)\r\n             ||  ex.target.toLowerCase().includes(search)   \r\n             ||  ex.equipment.toLowerCase().includes(search)   \r\n             ||  ex.bodyPart.toLowerCase().includes(search)        \r\n            )\r\n           console.log(searchedExercices.length)\r\n           if(searchedExercices.length === 0)\r\n           {\r\n            props.setNoExercisesFound(true)\r\n           }\r\n           else {\r\n            props.setExercices(searchedExercices)\r\n           \r\n           }\r\n           \r\n           setSearch('')\r\n        }\r\n        searchHandler()\r\n    }\r\n  },[search])\r\n\r\n\r\n    const commands = [\r\n        {\r\n          command: 'reset',\r\n          callback: () => resetTranscript()\r\n        },\r\n        // {\r\n        //   command: 'shut up',\r\n        //   callback: () => setMessage('I wasn\\'t talking.')\r\n        // },\r\n        // {\r\n        //   command: 'Hello',\r\n        //   callback: () => setMessage('Hi there!')\r\n        // },\r\n      ]\r\n      const {\r\n        transcript,\r\n        interimTranscript,\r\n        finalTranscript,\r\n        resetTranscript,\r\n        listening,\r\n      } = useSpeechRecognition({ commands });\r\n     \r\n      useEffect(() => {\r\n        if (finalTranscript !== '') {\r\n          console.log('Got final result:', finalTranscript);\r\n        }\r\n        if(transcript.length > 0)\r\n        {\r\n            setSearch(transcript)\r\n        }\r\n      }, [interimTranscript, finalTranscript , transcript]);\r\n      if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n        return null;\r\n      }\r\n     \r\n      if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n        console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\r\n      }\r\n      const listenContinuously = () => {\r\n        SpeechRecognition.startListening({\r\n          language: 'en-GB',\r\n        });\r\n      };\r\n  return (\r\n    <>\r\n    {listening ? <img src={animated} onClick={SpeechRecognition.stopListening} className='microphone'/>\r\n    : <img src={micro} onClick={listenContinuously} className='microphone'/>\r\n  }\r\n  <p>{transcript}</p>\r\n  </>\r\n  )\r\n}\r\n\r\nexport default MicrophoneSearch"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA4BC,QAA5B,QAA2C,OAA3C;AACA,OAAOC,KAAP,MAAkB,uBAAlB;AACA,OAAOC,QAAP,MAAqB,uBAArB;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;AACA,SAAQC,YAAR,EAAqBC,SAArB,QAAqC,oBAArC;;;;AACA,MAAMC,gBAAgB,GAAIC,KAAD,IAAW;EAAA;;EAElC,MAAM,CAACC,MAAD,EAAUC,SAAV,IAAuBV,QAAQ,CAAC,EAAD,CAArC;EAEAD,SAAS,CAAE,MAAI;IAEb;IACA,IAAG,CAACU,MAAJ,EACA;MACI;IACH,CAHD,MAKK;MAED,MAAME,aAAa,GAAG,YAAU;QAC5BC,MAAM,CAACC,QAAP,CAAgB;UAACC,GAAG,EAAG,IAAP;UAAcC,QAAQ,EAAE;QAAxB,CAAhB;QACA,MAAMC,MAAM,GAAG,MAAMV,SAAS,CAAC,6CAAD,EAAgDD,YAAhD,CAA9B;QACA,MAAMY,iBAAiB,GAAGD,MAAM,CAACE,MAAP,CAAeC,EAAD,IACvCA,EAAE,CAACC,IAAH,CAAQC,WAAR,GAAsBC,QAAtB,CAA+Bb,MAA/B,KACIU,EAAE,CAACI,MAAH,CAAUF,WAAV,GAAwBC,QAAxB,CAAiCb,MAAjC,CADJ,IAEIU,EAAE,CAACK,SAAH,CAAaH,WAAb,GAA2BC,QAA3B,CAAoCb,MAApC,CAFJ,IAGIU,EAAE,CAACM,QAAH,CAAYJ,WAAZ,GAA0BC,QAA1B,CAAmCb,MAAnC,CAJqB,CAA1B;QAMDiB,OAAO,CAACC,GAAR,CAAYV,iBAAiB,CAACW,MAA9B;;QACA,IAAGX,iBAAiB,CAACW,MAAlB,KAA6B,CAAhC,EACA;UACCpB,KAAK,CAACqB,mBAAN,CAA0B,IAA1B;QACA,CAHD,MAIK;UACJrB,KAAK,CAACsB,YAAN,CAAmBb,iBAAnB;QAEA;;QAEDP,SAAS,CAAC,EAAD,CAAT;MACF,CApBD;;MAqBAC,aAAa;IAChB;EACF,CAjCQ,EAiCP,CAACF,MAAD,CAjCO,CAAT;EAoCE,MAAMsB,QAAQ,GAAG,CACb;IACEC,OAAO,EAAE,OADX;IAEEC,QAAQ,EAAE,MAAMC,eAAe;EAFjC,CADa,CAKb;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EAZa,CAAjB;EAcE,MAAM;IACJC,UADI;IAEJC,iBAFI;IAGJC,eAHI;IAIJH,eAJI;IAKJI;EALI,IAMFlC,oBAAoB,CAAC;IAAE2B;EAAF,CAAD,CANxB;EAQAhC,SAAS,CAAC,MAAM;IACd,IAAIsC,eAAe,KAAK,EAAxB,EAA4B;MAC1BX,OAAO,CAACC,GAAR,CAAY,mBAAZ,EAAiCU,eAAjC;IACD;;IACD,IAAGF,UAAU,CAACP,MAAX,GAAoB,CAAvB,EACA;MACIlB,SAAS,CAACyB,UAAD,CAAT;IACH;EACF,CARQ,EAQN,CAACC,iBAAD,EAAoBC,eAApB,EAAsCF,UAAtC,CARM,CAAT;;EASA,IAAI,CAAChC,iBAAiB,CAACoC,gCAAlB,EAAL,EAA2D;IACzD,OAAO,IAAP;EACD;;EAED,IAAI,CAACpC,iBAAiB,CAACoC,gCAAlB,EAAL,EAA2D;IACzDb,OAAO,CAACC,GAAR,CAAY,uFAAZ;EACD;;EACD,MAAMa,kBAAkB,GAAG,MAAM;IAC/BrC,iBAAiB,CAACsC,cAAlB,CAAiC;MAC/BC,QAAQ,EAAE;IADqB,CAAjC;EAGD,CAJD;;EAKJ,oBACE;IAAA,WACCJ,SAAS,gBAAG;MAAK,GAAG,EAAEpC,QAAV;MAAoB,OAAO,EAAEC,iBAAiB,CAACwC,aAA/C;MAA8D,SAAS,EAAC;IAAxE;MAAA;MAAA;MAAA;IAAA,QAAH,gBACR;MAAK,GAAG,EAAE1C,KAAV;MAAiB,OAAO,EAAEuC,kBAA1B;MAA8C,SAAS,EAAC;IAAxD;MAAA;MAAA;MAAA;IAAA,QAFF,eAIF;MAAA,UAAIL;IAAJ;MAAA;MAAA;MAAA;IAAA,QAJE;EAAA,gBADF;AAQD,CA3FD;;GAAM5B,gB;UA4DIH,oB;;;KA5DJG,gB;AA6FN,eAAeA,gBAAf"},"metadata":{},"sourceType":"module"}