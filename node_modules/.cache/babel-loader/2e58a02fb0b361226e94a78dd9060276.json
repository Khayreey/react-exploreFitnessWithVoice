{"ast":null,"code":"var _jsxFileName = \"H:\\\\React\\\\FREE-CODE-CAMP\\\\fitness\\\\src\\\\components\\\\MicrophoneSearch.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect } from 'react';\nimport micro from '../assets/icons/m.png';\nimport animated from '../assets/icons/m.gif';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nconst MicrophoneSearch = () => {\n  _s();\n\n  const searchHandler = async () => {\n    if (search) {\n      const exData = await fetchData('https://exercisedb.p.rapidapi.com/exercises', exGetOptions);\n      const searchedExercices = exData.filter(ex => ex.name.toLowerCase().includes(search) || ex.target.toLowerCase().includes(search) || ex.equipment.toLowerCase().includes(search) || ex.bodyPart.toLowerCase().includes(search));\n      setSearch('');\n      props.setExercices(searchedExercices);\n    } else {\n      setSearchError(true);\n    }\n  };\n\n  const commands = [{\n    command: 'reset',\n    callback: () => resetTranscript()\n  } // {\n  //   command: 'shut up',\n  //   callback: () => setMessage('I wasn\\'t talking.')\n  // },\n  // {\n  //   command: 'Hello',\n  //   callback: () => setMessage('Hi there!')\n  // },\n  ];\n  const {\n    transcript,\n    interimTranscript,\n    finalTranscript,\n    resetTranscript,\n    listening\n  } = useSpeechRecognition({\n    commands\n  });\n  useEffect(() => {\n    if (finalTranscript !== '') {\n      console.log('Got final result:', finalTranscript);\n    }\n  }, [interimTranscript, finalTranscript]);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\n  }\n\n  const listenContinuously = () => {\n    SpeechRecognition.startListening({\n      language: 'en-GB'\n    });\n  };\n\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [listening ? /*#__PURE__*/_jsxDEV(\"img\", {\n      src: animated,\n      onClick: SpeechRecognition.stopListening,\n      className: \"microphone\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 67,\n      columnNumber: 18\n    }, this) : /*#__PURE__*/_jsxDEV(\"img\", {\n      src: micro,\n      onClick: listenContinuously,\n      className: \"microphone\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: transcript\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 70,\n      columnNumber: 3\n    }, this)]\n  }, void 0, true);\n};\n\n_s(MicrophoneSearch, \"+WXvEF5VkOiNRD1u9ZjMy0S3Bs4=\", false, function () {\n  return [useSpeechRecognition];\n});\n\n_c = MicrophoneSearch;\nexport default MicrophoneSearch;\n\nvar _c;\n\n$RefreshReg$(_c, \"MicrophoneSearch\");","map":{"version":3,"names":["React","useEffect","micro","animated","SpeechRecognition","useSpeechRecognition","MicrophoneSearch","searchHandler","search","exData","fetchData","exGetOptions","searchedExercices","filter","ex","name","toLowerCase","includes","target","equipment","bodyPart","setSearch","props","setExercices","setSearchError","commands","command","callback","resetTranscript","transcript","interimTranscript","finalTranscript","listening","console","log","browserSupportsSpeechRecognition","listenContinuously","startListening","language","stopListening"],"sources":["H:/React/FREE-CODE-CAMP/fitness/src/components/MicrophoneSearch.js"],"sourcesContent":["import React , {useEffect} from 'react'\r\nimport micro from '../assets/icons/m.png'\r\nimport animated from '../assets/icons/m.gif'\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\nconst MicrophoneSearch = () => {\r\n\r\n\r\n    const searchHandler = async ()=> {\r\n        if(search)\r\n        {\r\n            const exData = await fetchData('https://exercisedb.p.rapidapi.com/exercises', exGetOptions)\r\n            const searchedExercices = exData.filter((ex)=>\r\n             ex.name.toLowerCase().includes(search)\r\n             ||  ex.target.toLowerCase().includes(search)   \r\n             ||  ex.equipment.toLowerCase().includes(search)   \r\n             ||  ex.bodyPart.toLowerCase().includes(search)        \r\n            )\r\n           setSearch('')\r\n           props.setExercices(searchedExercices)\r\n        }\r\n        else {\r\n            setSearchError(true)\r\n        }\r\n    }\r\n\r\n    const commands = [\r\n        {\r\n          command: 'reset',\r\n          callback: () => resetTranscript()\r\n        },\r\n        // {\r\n        //   command: 'shut up',\r\n        //   callback: () => setMessage('I wasn\\'t talking.')\r\n        // },\r\n        // {\r\n        //   command: 'Hello',\r\n        //   callback: () => setMessage('Hi there!')\r\n        // },\r\n      ]\r\n      const {\r\n        transcript,\r\n        interimTranscript,\r\n        finalTranscript,\r\n        resetTranscript,\r\n        listening,\r\n      } = useSpeechRecognition({ commands });\r\n     \r\n      useEffect(() => {\r\n        if (finalTranscript !== '') {\r\n          console.log('Got final result:', finalTranscript);\r\n        }\r\n      }, [interimTranscript, finalTranscript]);\r\n      if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n        return null;\r\n      }\r\n     \r\n      if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\r\n        console.log('Your browser does not support speech recognition software! Try Chrome desktop, maybe?');\r\n      }\r\n      const listenContinuously = () => {\r\n        SpeechRecognition.startListening({\r\n          language: 'en-GB',\r\n        });\r\n      };\r\n  return (\r\n    <>\r\n    {listening ? <img src={animated} onClick={SpeechRecognition.stopListening} className='microphone'/>\r\n    : <img src={micro} onClick={listenContinuously} className='microphone'/>\r\n  }\r\n  <p>{transcript}</p>\r\n  </>\r\n  )\r\n}\r\n\r\nexport default MicrophoneSearch"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAgC,OAAhC;AACA,OAAOC,KAAP,MAAkB,uBAAlB;AACA,OAAOC,QAAP,MAAqB,uBAArB;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;;AACA,MAAMC,gBAAgB,GAAG,MAAM;EAAA;;EAG3B,MAAMC,aAAa,GAAG,YAAW;IAC7B,IAAGC,MAAH,EACA;MACI,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAAC,6CAAD,EAAgDC,YAAhD,CAA9B;MACA,MAAMC,iBAAiB,GAAGH,MAAM,CAACI,MAAP,CAAeC,EAAD,IACvCA,EAAE,CAACC,IAAH,CAAQC,WAAR,GAAsBC,QAAtB,CAA+BT,MAA/B,KACIM,EAAE,CAACI,MAAH,CAAUF,WAAV,GAAwBC,QAAxB,CAAiCT,MAAjC,CADJ,IAEIM,EAAE,CAACK,SAAH,CAAaH,WAAb,GAA2BC,QAA3B,CAAoCT,MAApC,CAFJ,IAGIM,EAAE,CAACM,QAAH,CAAYJ,WAAZ,GAA0BC,QAA1B,CAAmCT,MAAnC,CAJqB,CAA1B;MAMDa,SAAS,CAAC,EAAD,CAAT;MACAC,KAAK,CAACC,YAAN,CAAmBX,iBAAnB;IACF,CAXD,MAYK;MACDY,cAAc,CAAC,IAAD,CAAd;IACH;EACJ,CAhBD;;EAkBA,MAAMC,QAAQ,GAAG,CACb;IACEC,OAAO,EAAE,OADX;IAEEC,QAAQ,EAAE,MAAMC,eAAe;EAFjC,CADa,CAKb;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EAZa,CAAjB;EAcE,MAAM;IACJC,UADI;IAEJC,iBAFI;IAGJC,eAHI;IAIJH,eAJI;IAKJI;EALI,IAMF3B,oBAAoB,CAAC;IAAEoB;EAAF,CAAD,CANxB;EAQAxB,SAAS,CAAC,MAAM;IACd,IAAI8B,eAAe,KAAK,EAAxB,EAA4B;MAC1BE,OAAO,CAACC,GAAR,CAAY,mBAAZ,EAAiCH,eAAjC;IACD;EACF,CAJQ,EAIN,CAACD,iBAAD,EAAoBC,eAApB,CAJM,CAAT;;EAKA,IAAI,CAAC3B,iBAAiB,CAAC+B,gCAAlB,EAAL,EAA2D;IACzD,OAAO,IAAP;EACD;;EAED,IAAI,CAAC/B,iBAAiB,CAAC+B,gCAAlB,EAAL,EAA2D;IACzDF,OAAO,CAACC,GAAR,CAAY,uFAAZ;EACD;;EACD,MAAME,kBAAkB,GAAG,MAAM;IAC/BhC,iBAAiB,CAACiC,cAAlB,CAAiC;MAC/BC,QAAQ,EAAE;IADqB,CAAjC;EAGD,CAJD;;EAKJ,oBACE;IAAA,WACCN,SAAS,gBAAG;MAAK,GAAG,EAAE7B,QAAV;MAAoB,OAAO,EAAEC,iBAAiB,CAACmC,aAA/C;MAA8D,SAAS,EAAC;IAAxE;MAAA;MAAA;MAAA;IAAA,QAAH,gBACR;MAAK,GAAG,EAAErC,KAAV;MAAiB,OAAO,EAAEkC,kBAA1B;MAA8C,SAAS,EAAC;IAAxD;MAAA;MAAA;MAAA;IAAA,QAFF,eAIF;MAAA,UAAIP;IAAJ;MAAA;MAAA;MAAA;IAAA,QAJE;EAAA,gBADF;AAQD,CApED;;GAAMvB,gB;UAyCID,oB;;;KAzCJC,gB;AAsEN,eAAeA,gBAAf"},"metadata":{},"sourceType":"module"}